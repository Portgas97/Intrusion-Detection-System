{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bcc6be9a",
   "metadata": {},
   "source": [
    "# Artificial Intelligence for Cybersecurity Project\n",
    "**Venturini Francesco** No. 548415"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "94466195",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics.cluster import contingency_matrix\n",
    "from sklearn.metrics import homogeneity_completeness_v_measure\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.neighbors import LocalOutlierFactor as LOF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e023a4a2",
   "metadata": {},
   "source": [
    "# Dataset description and Goal\n",
    "The dataset that has been chosen for the project is the **`UNSW-NB15`  dataset**, created by the IXIA PerfectStorm tool \n",
    "in the Cyber Range Lab of the Australian Centre for Cyber Security (ACCS) for generating a \n",
    "hybrid of real modern normal activities and synthetic contemporary attack behaviours. Tcpdump \n",
    "tool is utilised to capture 100 GB of the raw traffic (e.g., Pcap files). This data set has nine \n",
    "families of attacks, namely, `Fuzzers`, `Analysis`, `Backdoors`, `DoS`, `Exploits`, `Generic`, \n",
    "`Reconnaissance`, `Shellcode` and `Worms`. The Argus, Bro-IDS tools are utilised and twelve \n",
    "algorithms are developed to generate totally 49 features with the class label. These features are \n",
    "described in `UNSW-NB15_freatures.csv` file. The total number of records is two millions and \n",
    "540,044 which are stored in the four CSV files, namely, `UNSW-NB15_1.csv`, `UNSW-NB15_2.csv`, `UNSW-NB15_3.csv` and `UNSW-NB15_4.csv`. The ground truth table is named \n",
    "`UNSW-NB15_GT.csv` and the list of event file is called `UNSW-NB15_LIST_EVENTS.csv`. A\n",
    "partition from this data set is configured as a training set and testing set, namely, \n",
    "`UNSW_NB15_training-set.csv` and `UNSW_NB15_testing-set.csv` respectively. The number of \n",
    "records in the training set is 82,332 records and the testing set is 175,341 records from different \n",
    "the types of attack and normal.\n",
    "\n",
    "Input data files are available in the `datasets/UNSW-NB15` directory. The next cell will list all files under this directory.\n",
    "\n",
    "The goal of this project is to devise a general classifier that categorizes each individual sample as one of the nine classes\n",
    "seen before, with an appropriate accuracy and other performance metrics that will be evaluated and compared with existent works in the dedicated paragraph. \n",
    "\n",
    "The followed procedure is the classical one of the Data Mining process, thus:\n",
    "\n",
    "1) **Data acquisition and exploration**: first phase with data harvesting \n",
    "\n",
    "2) **Data cleaning**: duplicate removal, missing values manage, erroneous data and other problems that affect data quality\n",
    "\n",
    "3) **Data selection**: find relevant data for the analysis \n",
    "\n",
    "4) **Pre-processing**: data transformation in more useful formats (like standardization and categorical-variables encoding)\n",
    "\n",
    "5) **Data modelling**: applying machine learning and data mining algorithms to build models that describes the data\n",
    "\n",
    "6) **Evaluation**: accuracy of the model and its ability to predict future values\n",
    "\n",
    "7) **Results interpretation**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2bf21b50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../datasets/UNSW-NB15/The UNSW-NB15 description.pdf\n",
      "../datasets/UNSW-NB15/UNSW-NB15_1.csv\n",
      "../datasets/UNSW-NB15/UNSW-NB15_2.csv\n",
      "../datasets/UNSW-NB15/UNSW-NB15_3.csv\n",
      "../datasets/UNSW-NB15/UNSW-NB15_4.csv\n",
      "../datasets/UNSW-NB15/UNSW-NB15_features.csv\n",
      "../datasets/UNSW-NB15/UNSW-NB15_GT.csv\n",
      "../datasets/UNSW-NB15/UNSW-NB15_LIST_EVENTS.csv\n",
      "../datasets/UNSW-NB15/a part of training and testing set\\UNSW_NB15_testing-set.csv\n",
      "../datasets/UNSW-NB15/a part of training and testing set\\UNSW_NB15_training-set.csv\n"
     ]
    }
   ],
   "source": [
    "for dirname, _, filenames in os.walk('../datasets/UNSW-NB15/'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f55db28e",
   "metadata": {},
   "source": [
    "# 1. Data Acquisition and Exlporation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26f34381",
   "metadata": {},
   "source": [
    "Pandas utilities are used to retireve the dataset from the CSV files. The result of read_csv is stored into a DataFrame data structure, e.g., a two-dimensional table-like form. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fce9fb25",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_root = '../datasets/UNSW-NB15/'\n",
    "\n",
    "# datasets are switched\n",
    "test = pd.read_csv(dataset_root + 'a part of training and testing set/UNSW_NB15_training-set.csv')\n",
    "train = pd.read_csv(dataset_root + 'a part of training and testing set/UNSW_NB15_testing-set.csv')\n",
    "\n",
    "# otherwise UTF-8 decoding error, Windows codepage 1252 is used\n",
    "features = pd.read_csv(dataset_root + 'UNSW-NB15_features.csv', encoding='cp1252').set_index('No.') \n",
    "list_events = pd.read_csv(dataset_root + 'UNSW-NB15_LIST_EVENTS.csv')\n",
    "\n",
    "# train and test set concatenation\n",
    "train['type'] = 'train'\n",
    "test['type'] = 'test'\n",
    "df_total = pd.concat([train, test], axis=0, ignore_index=True)\n",
    "\n",
    "# to see all the columns in outputs\n",
    "pd.set_option('display.max_columns', None) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdcbde2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_total"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15a8d2da",
   "metadata": {},
   "source": [
    "Let's see the dimensionality and an extract of the content:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50ebae22",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(f\"Training set shape: {train.shape}\\n\")\n",
    "print(f\"Test set shape: {test.shape}\\n\")\n",
    "print(f\"Total set shape: {df_total.shape}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d3cef7a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# thanks to https://www.kaggle.com/code/khairulislam/unsw-nb15-eda?scriptVersionId=27690564&cellId=8\n",
    "from pandas.api.types import is_datetime64_any_dtype as is_datetime\n",
    "from pandas.api.types import is_categorical_dtype\n",
    "def reduce_mem_usage(df, use_float16=False):\n",
    "    \"\"\" iterate through all the columns of a dataframe and modify the data type\n",
    "        to reduce memory usage.        \n",
    "    \"\"\"\n",
    "    start_mem = df.memory_usage().sum() / 1024**2\n",
    "    print('Memory usage of dataframe is {:.2f} MB'.format(start_mem))\n",
    "    \n",
    "    for col in df.columns:\n",
    "        if is_datetime(df[col]) or is_categorical_dtype(df[col]):\n",
    "            # skip datetime type or categorical type\n",
    "            continue\n",
    "        col_type = df[col].dtype\n",
    "        \n",
    "        if col_type != object:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)  \n",
    "            else:\n",
    "                if use_float16 and c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)\n",
    "        else:\n",
    "            df[col] = df[col].astype('object')\n",
    "    end_mem = df.memory_usage().sum() / 1024**2\n",
    "    print('Memory usage after optimization is: {:.2f} MB'.format(end_mem))\n",
    "    print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) / start_mem))\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fafa5688",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_total = reduce_mem_usage(df_total)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da2d4645",
   "metadata": {},
   "source": [
    "## Feature statistics "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfbf8f07",
   "metadata": {},
   "source": [
    "Attack categories:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feaf4da8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "list_events['Attack category'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d37bd7c3",
   "metadata": {},
   "source": [
    "Attack subcategories: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eebf084",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_events['Attack subcategory'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7e9ed93",
   "metadata": {},
   "source": [
    "The features and the relative descriptions are in the next cell. Note that `srcip`, `sport`, `dstip`, `dsport` are not present in the training set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b05c5ef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# actually 45 are present in the dataset\n",
    "features.head(features.shape[0]) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "144598c2",
   "metadata": {},
   "source": [
    "Print some information on the individual attributes, checking also the number of null instances:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a10579c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for i, col_name in enumerate(train.columns):  \n",
    "  print(\"{0:16}\".format(col_name), \" \\tn_unique = {0:6}\".format(train[col_name].nunique()), \n",
    "        \"---> {0:5}%\".format(round((100*train[col_name].nunique()/len(train[col_name])),2)),\n",
    "        \"\\tnull_count = {}\".format(train[col_name].isnull().sum())) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66db9110",
   "metadata": {},
   "source": [
    "Let's see the description of the features (including non-numerical attributes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94a508a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.describe(include='all') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c763a79",
   "metadata": {},
   "source": [
    "## TO DO comments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a569c40",
   "metadata": {},
   "source": [
    "We can take a look at the training data class distribution (10 category breakdown):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4d28d40",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_attack_cats = train['attack_cat'].value_counts()\n",
    "train_attack_cats.plot(kind='barh', figsize=(20,10), fontsize=20);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc150c27",
   "metadata": {},
   "source": [
    "The same plot as before in a logarithmic representation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d4d4eb1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_attack_cats.plot(kind='barh', logx=True, figsize=(20,10), fontsize=20);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d091168",
   "metadata": {},
   "source": [
    "One obvious observation is that the classes are tremendously imbalanced. For instance, the `Worms` class is smaller than the `Exploits` class. If we ignore this class imbalance and use the training data as is, there is a chance that the model will learn a lot more about, e.g., the `Normal` and the `Generic` classes compared to the `Worms` and `Shellcode` classes, which can result in an undesirable bias in the classifier. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c97191f",
   "metadata": {},
   "source": [
    "Now, let's take a look at some data. Data visualization provides many additional techniques for viewing data through graphical means. These can help in identifying relations, trends, and biases \"hidden\" in unstructured data sets. \n",
    "\n",
    "# TO DO questo va capito e commentato / utilizzato"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea22f924",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_to_plot = train.copy().drop(['id'], axis=1) # useless\n",
    "df_columns = df_to_plot.columns\n",
    "\n",
    "for i, var in enumerate(df_columns):\n",
    "    max_largest = 30\n",
    "\n",
    "    largest = min(max_largest, df_to_plot[var].nunique())\n",
    "    n_nunique_var = df_to_plot[var].nunique()\n",
    "    tot = len(df_to_plot[var])\n",
    "    n_null = df_to_plot[var].isnull().sum() \n",
    "\n",
    "    plt.figure(figsize = (14, 6))\n",
    "    ax = sns.countplot(x = var, order = df_to_plot[var].value_counts().iloc[:largest].index, data=df_to_plot)\n",
    "    plt.xticks(rotation = 90,fontsize = 12)\n",
    "    plt.yticks(fontsize = 12)\n",
    "    plt.xlabel(var, fontsize = 18)\n",
    "    plt.ylabel('COUNT', fontsize = 18)\n",
    "\n",
    "    if max_largest == largest:\n",
    "      plt.title(f'{var} countplot (zoom over the largest {largest} (n_unique= {n_nunique_var}))', fontsize = 15)\n",
    "    else:\n",
    "        plt.title(f'{var} countplot', fontsize = 18)\n",
    "\n",
    "    plt.grid(axis = 'y')\n",
    "\n",
    "    for p in ax.patches:\n",
    "        percentage = '{:.0f}\\n{:.1f}%'.format(p.get_height(), 100 * p.get_height() / len(df_to_plot[var]))\n",
    "        x = p.get_x() + p.get_width()\n",
    "        y = p.get_height()\n",
    "        ax.annotate(percentage, (x,y), ha='right', va='bottom')\n",
    "\n",
    "    # plt.savefig(workdir + '/fig/{}_largest_{}.png'.format(var, largest), format = 'png')\n",
    "\n",
    "    if max_largest == largest: \n",
    "      plt.figure(figsize = (14, 6))\n",
    "      # print(\"plotting also smallest \")\n",
    "      ax_lower = sns.countplot(x = var, order = df_to_plot[var].value_counts().iloc[-largest:].index, data = df_to_plot)\n",
    "      plt.xticks(rotation = 90, fontsize = 12)\n",
    "      plt.yticks(fontsize = 12)\n",
    "      plt.xlabel(var, fontsize = 18)\n",
    "      plt.ylabel('COUNT', fontsize = 18)\n",
    "      plt.title(f'{var} countplot (zoom over the smallest {largest} (n_unique= {n_nunique_var}))',fontsize = 15)\n",
    "\n",
    "      plt.grid(axis='y')\n",
    "\n",
    "      for p in ax_lower.patches:\n",
    "        percentage = '{:.0f}\\n{:.1f}%'.format(p.get_height(), 100 * p.get_height() / len(df_to_plot[var]))\n",
    "        x = p.get_x() + p.get_width()\n",
    "        y = p.get_height()\n",
    "        ax_lower.annotate(percentage, (x,y), ha='right', va='bottom')\n",
    "\n",
    "      # plt.savefig(workdir + '/fig/{}_smallest_{}.png'.format(var, largest), format = 'png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8356c682",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_to_plot.hist(figsize=(22,22));"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d1ea007",
   "metadata": {},
   "source": [
    "### Datatypes understanding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bd0344b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_total.dtypes # data types of each column, mixed types are stored with the `object` dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f88990b",
   "metadata": {},
   "source": [
    "From the previous output, the describe output and the specification of the dataset in the documentation, we can see the presence of:\n",
    "- 3 categorical features (*dur*, *proto*, *service*)\n",
    "- 2 (asymmetric) binary features (*is_ftp_login*, *is_sm_ips_ports*)\n",
    "- 2 possible target features (*attack_cat*, *label*)\n",
    "- the *others* are numerical features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "535751fe",
   "metadata": {},
   "source": [
    "## Look at some features for a specific attack\n",
    "This paragraph it is not aimed at a deep data visualization analysis of the dataset but is useful to understand some insights.  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23dbfabf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fuzzers_df = df_total[df_total['attack_cat'] == 'Fuzzers' ]\n",
    "fuzzers_df.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86cb3f93",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fuzzers_df.hist(figsize=(20,20));"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08d5e2ce",
   "metadata": {},
   "source": [
    "With the general distributions we can spot some differences, like in the values taken in sttl and dttl. But also, for example, the maximum values of dur, spkts, dkpts, sbytes, dbytes, and a lot more. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e265e53",
   "metadata": {},
   "source": [
    "If we analyse the tendency of two attributes like *is_ftp_login* and *dur* we can, for example, spot that attacks belonging to the Exploit category are characterized by a higher value of the former feature (note that the attribute is binary but assumes values higher than 1, data cleaning is a step performed ahead), meanwhile no insights come from the latter one. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed4d9632",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.lmplot(x=\"dur\", y=\"is_ftp_login\", data=df_total, hue=\"attack_cat\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aea953f",
   "metadata": {},
   "source": [
    "Take a look at categorical values for different attack categories:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7721c707",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install -U kaleido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83b9cc42",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "nominal_cols = train.select_dtypes(include='object').columns\n",
    "for feature in nominal_cols:\n",
    "    fig = px.histogram(train, x=feature, log_y=True, color=\"attack_cat\", color_discrete_sequence=px.colors.qualitative.Light24)\n",
    "    fig.update_layout(xaxis={'categoryorder':'total ascending'})\n",
    "    fig.show(renderer=\"svg\", width=900, height=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44cd203e",
   "metadata": {},
   "source": [
    "Let's do the same for the numeric attributes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6197e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_cols = train.select_dtypes(exclude='object').columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93a3128a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for feature in numeric_cols:\n",
    "    fig = px.histogram(train, x=feature, log_y=True, color=\"attack_cat\", color_discrete_sequence=px.colors.qualitative.Light24)\n",
    "    fig.show(renderer=\"svg\", width=900, height=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7eac447",
   "metadata": {},
   "source": [
    "# 2. Data cleaning\n",
    "\n",
    "The data cleaning phase is applied both to the training and the test set. It is an important phase because data quality has an high impact on the precision and the accuracy of the machine learning models. It is important to manage both the sets in the same manner to gurantee that the models will be evaluated equally and in a reliable manner. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a94b5853",
   "metadata": {},
   "source": [
    "Data in real word is dirty. The may be:\n",
    "- incomplete (missing values)\n",
    "- noisy (containing noise, errors, outliers)\n",
    "- inconsitent (containing dicrepancies)\n",
    "- intentional "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a08f636e",
   "metadata": {},
   "source": [
    "Remove useless *id* column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bb1e631",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_total.drop(['id'], axis=1, inplace=True) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60dc1f04",
   "metadata": {},
   "source": [
    "TO DO comment this (EDA, data preprocessing...):"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a892b4dd",
   "metadata": {},
   "source": [
    "Some utility variable for different feature types:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14c14590",
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrieve features based on their types\n",
    "col_names = np.array(df_total.columns)\n",
    "nominal_idx = [1, 2, 3] # indexes of nominal features\n",
    "binary_idx =  [36, 41] # indexes of binary features\n",
    "target_idx = [42, 43, 44] # attack category, label and utility column for splitting\n",
    "numeric_idx = list(set(range(43)).difference(nominal_idx).difference(binary_idx).difference(target_idx)) # indexes of numerical features\n",
    "\n",
    "\n",
    "nominal_cols = col_names[nominal_idx].tolist()\n",
    "binary_cols = col_names[binary_idx].tolist()\n",
    "target_cols = col_names[target_idx].tolist()\n",
    "numeric_cols = col_names[numeric_idx].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd12150e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"Check on cols assignment:\")\n",
    "print(f\"nominal_cols = {nominal_cols}\\n\")\n",
    "print(f\"binary_cols  = {binary_cols}\\n\")\n",
    "print(f\"target_cols  = {target_cols}\\n\")\n",
    "print(f\"numeric_cols = {numeric_cols}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51d7ea3a",
   "metadata": {},
   "source": [
    "### Missing values check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1719861",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_total.isnull().values.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49634674",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # TEST \n",
    "\n",
    "# # L'idea dovrebbe andare bene, \n",
    "# # il problema ora è riportare il tutto a come era prima (service categorico, attack_cat non encoded etc. )\n",
    "# # forse la cosa migliore è lavorare nel dataset originale riga per riga in modo da sapere dove andare a mettere\n",
    "# # il valore calcolato\n",
    "\n",
    "# from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# multi_data = df_total.copy()\n",
    "# multi_data.drop('label', axis=1, inplace=True)\n",
    "# multi_label = pd.DataFrame(multi_data.service)\n",
    "# # multi_data = pd.get_dummies(multi_data,columns=['service']) secondo me non necessario TO DO delete?\n",
    "\n",
    "# le2 = LabelEncoder()\n",
    "# enc_label = multi_label.apply(le2.fit_transform)\n",
    "# multi_data['service'] = enc_label # '-' is encoded as 0\n",
    "\n",
    "# multi_data \n",
    "# multi_data = pd.get_dummies(multi_data, columns=['proto', 'state', 'attack_cat'], drop_first=True) # one-hot encoding\n",
    "\n",
    "# test_service = multi_data[multi_data['service'] == 0]\n",
    "# train_service = multi_data[multi_data['service'] > 0]\n",
    "\n",
    "# train_service_y = train_service['service']\n",
    "# train_service_x = train_service.drop(['service'], axis=1)\n",
    "\n",
    "# test_service_y = test_service['service']\n",
    "# test_service_x = test_service.drop(['service'], axis=1)\n",
    "\n",
    "# # ------------------------------------------------------\n",
    "\n",
    "# classifier = DecisionTreeClassifier(random_state=0)\n",
    "# classifier = classifier.fit(train_service_x, train_service_y)\n",
    "# pred_y = classifier.predict(test_service_x)\n",
    "   \n",
    "# # to have the same schema\n",
    "# prova = test_service.drop('service', axis=1)\n",
    "# prova['service'] = pred_y.tolist()\n",
    "# temp_col = prova.pop('service')\n",
    "# prova.insert(0, 'service', temp_col)\n",
    "\n",
    "# temp_col = train_service.pop('service')\n",
    "# train_service.insert(0, 'service', temp_col)\n",
    "\n",
    "# new_df = pd.concat([train_service, prova], ignore_index=True)\n",
    "# new_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "500bee50",
   "metadata": {},
   "source": [
    "### Consistency checking"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "372698d5",
   "metadata": {},
   "source": [
    "Let's take a look at the binary features (index and column transposition is used).\n",
    "\n",
    "By definition, all of these features should have a min of 0.0 and a max of 1.0\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba6375a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_total[binary_cols].describe().transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8678d98b",
   "metadata": {},
   "source": [
    "The `is_ftp_login` has a maximum value of 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4daeb37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The is_ftp_login column has a max value of 2.0\n",
    "df_total.groupby(['is_ftp_login']).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b32da2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.histogram(train, x='is_ftp_login', log_y=True, color=\"attack_cat\", color_discrete_sequence=px.colors.qualitative.Light24)\n",
    "fig.update_layout(xaxis={'categoryorder':'total ascending'})\n",
    "fig.show(renderer=\"svg\", width=900, height=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1f73400",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's fix this discrepancy and assume that: \n",
    "# is_ftp_login == 2 ==> 0 \n",
    "# is_ftp_login == 4 ==> 1\n",
    "df_total['is_ftp_login'].replace(2, 0, inplace=True)\n",
    "df_total['is_ftp_login'].replace(4, 1, inplace=True)\n",
    "df_total.groupby(['is_ftp_login']).size()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a40a9c05",
   "metadata": {},
   "source": [
    "### Checking for single-value features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "793726ac",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_total.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50942f15",
   "metadata": {},
   "source": [
    "### TODO data scrubbling? Data auditing? Slide page 31 Marcelloni"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71511ffc",
   "metadata": {},
   "source": [
    "### Duplicates check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b78bb44e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd5cb9dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "test.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de5791e0",
   "metadata": {},
   "source": [
    "# NO SMOOTHING, WHY? (TO NOT DELETE OUTLIERS?) TO DO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3a1ca99",
   "metadata": {},
   "source": [
    "## Balance checking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "979cf9f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['attack_cat'].unique() # performed only on the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c828f21e",
   "metadata": {},
   "outputs": [],
   "source": [
    "wedges = train['attack_cat'].value_counts()\n",
    "myexplode = [0, 0.04, 0.04, 0.04, 0.15, 0.2, 0.3, 0.7, 1.3, 2]\n",
    "plt.pie(np.array(wedges), labels= wedges.index, explode=myexplode, rotatelabels=True)\n",
    "plt.show()\n",
    "# classes.plot(kind = 'pie', figsize=(15,15), rot=0);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cf64180",
   "metadata": {},
   "source": [
    "We may have some problems with the `Analysis`,`Backdoor`, `Shellcode`, and `Worms` classes. The resolution of the class imbalance problem is ahead in the notebook. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d3c4c54",
   "metadata": {},
   "source": [
    "### Correlation Analysis\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fc3802c",
   "metadata": {},
   "source": [
    "Correlation analysis it is most commonly performed on the training data. The purpose of performing correlation analysis on the training data is to identify the relationships between the independent variables (predictors) and the dependent variable (outcome). This information can then be used to inform the selection of predictors for a predictive model or to inform feature engineering efforts. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "469abe29",
   "metadata": {},
   "outputs": [],
   "source": [
    "correlations = df_total.corr()\n",
    "\n",
    "# Generate a mask for the upper triangle\n",
    "mask = np.triu(np.ones_like(correlations, dtype=bool))\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(18,14))\n",
    "\n",
    "# Generate a custom diverging colormap\n",
    "cmap = sns.diverging_palette(200, 20, as_cmap=True)\n",
    "\n",
    "sns.heatmap(correlations, mask=mask, cmap=cmap, vmax=.9, center=0,\n",
    "            square=True, linewidths=.1, cbar_kws={\"shrink\": .5})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41f1b0fa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def top_correlations(correlations, limit=0.9):\n",
    "    columns = correlations.columns\n",
    "    for i in range(correlations.shape[0]):\n",
    "        for j in range(i+1, correlations.shape[0]):\n",
    "            if correlations.iloc[i,j] >= limit or correlations.iloc[i,j] <= -limit:\n",
    "                print(f\"{columns[i]} <-> {columns[j]}  ==  {correlations.iloc[i,j]*100}\")\n",
    "\n",
    "top_correlations(correlations)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f6fee76",
   "metadata": {},
   "source": [
    "Most correlated features are :\n",
    "\n",
    "* spkts, sbytes, sloss\n",
    "* dpkts, dbytes, dloss\n",
    "* sinpkt, is_sm_ips_ports\n",
    "* swin, dwin\n",
    "* tcprtt, synack\n",
    "* ct_srv_src, ct_srv_dst, ct_dst_src_ltm, ct_src_dport_ltm, ct_dst_sport_ltm\n",
    "* is_ftp_login ct_ftp_cmd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6571e57f",
   "metadata": {},
   "source": [
    "We can easily visualize correlations in a scatter plot. In the cell below a strong positive correlations between the *dbytes* and the *dloss* features is shown. Other examples are provided below, but here the analysis is not exhaustive. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b0bddb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(x = 'dbytes', y = 'dloss', data = df_total); "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "835f1860",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(x = 'sbytes', y = 'spkts', data = df_total);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f9fc922",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(x = 'ct_dst_src_ltm', y = 'ct_srv_dst', data = df_total);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e44043d7",
   "metadata": {},
   "source": [
    "# 3. Data selection & 4. Data preparation\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6c3087d",
   "metadata": {},
   "source": [
    "This is an important step in the machine learning process, we have to select a significant data subset then used to learn a model. Data selection is performed to raise the quality of machine learning models and to improve the performance of the models with new data. This could include missing or duplicate data removing, the deletion of useless features or the selection of a subset of the most important features. This step can also include the modification of the data distribution to make the model stable if the dataset is unbalanced.  \n",
    "\n",
    "The data selection step can contain oversampling and undersampling methods. \n",
    "\n",
    "Oversampling consists in increasing the data quantity of a minority class within the dataset to guarantee a higher representability of that class. This step can be useful to prevent understimating machine learning model performance. \n",
    "\n",
    "Undersampling consists in the reduction of data quantità of a majority class within the dataset to stabilize the representation of different classes. This step can be useuful to prevent overstimating machine learning model performance.\n",
    "\n",
    "\n",
    "The pre-elaboration phase is fundamental and should be executed both on the train and the test set. This phase consists in a serie of steps, like data cleaning (already performed), normalization, feature transformation and selection, that aim at improve the quality and the usability of the data to perform an automatic learning. \n",
    "It's important that both the train and the test set will be treated in the same manner, to avoid models either to be disadvantaged or to introduce inconsistencies. For example, if normalization is performed only on the train set, but not on the test set, test set values could not be represented correcly and negatively affect the model evaluation. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38af5630",
   "metadata": {},
   "source": [
    "TO DO oversampling, under sampling, e quindi balancing si fanno qui"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcc9af54",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_count_df(col, data=df_total):\n",
    "    df = pd.DataFrame(data[col].value_counts().reset_index().values, columns = [col, 'count'])\n",
    "    df['percent'] = df['count'].values*100/data.shape[0]\n",
    "    return df.sort_values(by='percent', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95fadccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def corr(col1, col2='label', df=df_total):\n",
    "    return pd.concat([df[col1], df[col2]], axis=1).corr().iloc[0,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "081571af",
   "metadata": {},
   "source": [
    "### State"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e8884ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "col = 'state'\n",
    "# create_count_df(col, train) # to set the row below\n",
    "df_total.loc[~df_total[col].isin(['FIN', 'INT', 'CON', 'REQ', 'RST']), col] = 'others'\n",
    "create_count_df(col)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9e78526",
   "metadata": {},
   "source": [
    "### Service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d074717",
   "metadata": {},
   "outputs": [],
   "source": [
    "col = 'service'\n",
    "# create_count_df(col, train) # to set the row below\n",
    "df_total.loc[~df_total[col].isin(['-', 'dns', 'http', 'smtp', 'ftp-data', 'ftp', 'ssh', 'pop3']), col] = 'others'\n",
    "create_count_df(col)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1b6f23d",
   "metadata": {},
   "source": [
    "### Proto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb9b3156",
   "metadata": {},
   "outputs": [],
   "source": [
    "col = 'proto'\n",
    "create_count_df(col, train)\n",
    "# from the documentation we can see that some valuee are present in the \n",
    "# test set but not in the train set\n",
    "df_total.loc[df_total[col].isin(['igmp', 'icmp', 'rtp']), col] = 'igmp_icmp_rtp'\n",
    "df_total.loc[~df_total[col].isin(['tcp', 'udp', 'arp', 'ospf', 'igmp_icmp_rtp']), col] = 'others'\n",
    "create_count_df(col)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29da9bf8",
   "metadata": {},
   "source": [
    "### is_sm_ips_ports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fb46f1d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# is_sm_ips_ports, if it is 1 the connection is always normal\n",
    "ax = sns.catplot(x='is_sm_ips_ports', hue=\"label\", col=\"type\", data=df_total, kind=\"count\", height=5, legend=False, aspect=1.4)\n",
    "ax.set_titles(\"{col_name}\")\n",
    "ax.add_legend(loc='upper right',labels=['normal','attack'])\n",
    "plt.show(ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04766b35",
   "metadata": {},
   "source": [
    "### is_ftp_login"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7a64b20",
   "metadata": {},
   "source": [
    "This feature is highly correlated to *ct_ftp_cmd*. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f15590d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_total.drop('is_ftp_login', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cbb6a81",
   "metadata": {},
   "source": [
    "### ct_ftp_cmd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c76e8a8d",
   "metadata": {},
   "source": [
    "It has an high correlation with is_ftp_login and has a very low correlation with 'label'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aa310f5",
   "metadata": {},
   "source": [
    "### sbytes & dbytes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eea0a89",
   "metadata": {},
   "source": [
    "These features are highly correlated to the number of sent packets. Actually, we can say that *spkts* * *smean* = *sbytes*. These features are highly correlated to sloss and dloss, we can drop them. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb74f872",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_total.drop(['sbytes', 'dbytes'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9512435",
   "metadata": {},
   "source": [
    "### smean & dmean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84d5b3e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the distributions are skewed to the left\n",
    "train['smean'].hist(figsize=(5,5));\n",
    "train['dmean'].hist(figsize=(5,5));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5965f7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can drop smean and dmean after this computation\n",
    "df_total['smean_log'] = df_total['smean'].apply(np.log1p)\n",
    "df_total['dmean_log'] = df_total['dmean'].apply(np.log1p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f75c5dd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we obtain a better correlation\n",
    "print(corr('smean'), corr('dmean'), corr('smean_log'), corr('dmean_log'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba659157",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_total.drop(['smean', 'dmean'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4487c324",
   "metadata": {},
   "source": [
    "### spkts & dpkts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5852cc5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# also these features are skewed, drop them\n",
    "df_total['spkts_log'] = df_total['spkts'].apply(np.log1p)\n",
    "df_total['dpkts_log'] = df_total['dpkts'].apply(np.log1p)\n",
    "print(corr('spkts'), corr('dpkts'), corr('spkts_log'), corr('dpkts_log'))\n",
    "df_total.drop(['spkts', 'dpkts'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f842a13",
   "metadata": {},
   "source": [
    "### sloss & dloss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "486a8b11",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_total['sloss_log'] = df_total['sloss'].apply(np.log1p)\n",
    "df_total['dloss_log'] = df_total['dloss'].apply(np.log1p)\n",
    "print(corr('sloss'), corr('dloss'), corr('sloss_log'), corr('dloss_log'))\n",
    "df_total.drop(['sloss', 'dloss'], axis=1, inplace= True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7312b13",
   "metadata": {},
   "source": [
    "### swin & dwin\n",
    "binning is performed, TO DO?? è strano non so quanto sia utile (EDA)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21be551a",
   "metadata": {},
   "source": [
    "### stcpb & dtcpb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea893ba5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_total['stcpb_log'] = df_total['stcpb'].apply(np.log1p)\n",
    "df_total['dtcpb_log'] = df_total['dtcpb'].apply(np.log1p)\n",
    "print(corr('stcpb'), corr('dtcpb'), corr('stcpb_log'), corr('dtcpb_log'))\n",
    "df_total.drop(['stcpb', 'dtcpb'], axis=1, inplace= True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61650ee7",
   "metadata": {},
   "source": [
    "### tcprtt & synack & ackdat\n",
    "*cprtt* is just the sum of *synack* and *ackdat*, we can drop it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bc73be1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_total.drop(['tcprtt'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a08fe00",
   "metadata": {},
   "source": [
    "### response_body_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1be8e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_total['response_body_len_log'] = df_total['response_body_len'].apply(np.log1p)\n",
    "print(corr('response_body_len'), corr('response_body_len_log'))\n",
    "df_total.drop(['response_body_len'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "097d8eeb",
   "metadata": {},
   "source": [
    "### ct_srv_src & ct_srv_dst\n",
    "TO DO They are high correlated, should be checked if dropping one improves results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8daceeca",
   "metadata": {},
   "source": [
    "### sinpkt & dinpkt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5cac340",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sinpkt is highly correlated with is_sm_ips_ports, will dropping one of them benefit? TO DO check\n",
    "df_total['sinpkt_log'] = df_total['sinpkt'].apply(np.log1p)\n",
    "df_total['dinpkt_log'] = df_total['dinpkt'].apply(np.log1p)\n",
    "print(corr('sinpkt'), corr('dinpkt'), corr('sinpkt_log'), corr('dinpkt_log'))\n",
    "df_total.drop(['sinpkt', 'dinpkt'], axis=1, inplace= True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "881a2d65",
   "metadata": {},
   "source": [
    "### sload & dload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5fd2024",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_total['sload_log'] = df_total['sload'].apply(np.log1p)\n",
    "df_total['dload_log'] = df_total['dload'].apply(np.log1p)\n",
    "print(corr('sload'), corr('dload'), corr('sload_log'), corr('dload_log'))\n",
    "df_total.drop(['sload', 'dload'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b715c44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrieve original datasets \n",
    "train = df_total[df_total['type'] == 'train']\n",
    "test = df_total[df_total['type'] == 'test']\n",
    "\n",
    "# splitting the train set\n",
    "train_y = train['attack_cat'] \n",
    "train_y_label = train['label']\n",
    "train_x_raw = train.drop(['attack_cat', 'label'], axis=1) \n",
    "\n",
    "# splitting the test set\n",
    "test_y = test['attack_cat']\n",
    "test_y_label = test['label']\n",
    "test_x_raw = test.drop(['attack_cat', 'label'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c2e8f3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# combined train and test set, without the ground truth\n",
    "combined_df_raw = pd.concat([train_x_raw, test_x_raw])\n",
    "combined_df_raw_y = pd.concat([train_y_label, test_y_label])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57df94da",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# reduces the cardinality for some features, less occurring values are set to '-' \n",
    "# for feature in df_cat.columns:    \n",
    "#     if df_cat[feature].nunique() > 6:\n",
    "#         combined_df_raw[feature] = np.where(combined_df_raw[feature].isin(combined_df_raw[feature].value_counts().head().index), combined_df_raw[feature], '-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa8b7046",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# df_cat = combined_df_raw.select_dtypes(exclude=[np.number])\n",
    "# df_cat.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0db1724",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the first level of the categorical attribute, to avoi the so-called \"dummy variable trap\n",
    "# in which independent vairbales being closely correlated violates assumptions of independence in regression\n",
    "combined_df = pd.get_dummies(combined_df_raw, columns=nominal_cols, drop_first=True) # one-hot encoding\n",
    "\n",
    "# Store dummy variable features name\n",
    "dummy_variables = list(set(combined_df) - set(combined_df_raw))\n",
    "dummy_variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a8a5422",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = combined_df[combined_df['type'] == 'train']\n",
    "test_x = combined_df[combined_df['type'] == 'test']\n",
    "df_total.drop(['type'], axis=1, inplace=True)\n",
    "combined_df.drop(['type'], axis=1, inplace=True)\n",
    "train_x.drop(['type'], axis=1, inplace=True)\n",
    "test_x.drop(['type'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a12a1d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5083b404",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "68803a47",
   "metadata": {},
   "source": [
    "### Feature selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb877083",
   "metadata": {},
   "source": [
    "Now the problem of dimensionality reduction is assessed. In particular it could be needed for:\n",
    "- avoid the curse of dimensionality\n",
    "- help in eliminating irrelevant features and reduce noise\n",
    "- reduce time and space required\n",
    "- allow easier visualization\n",
    "\n",
    "This step is not always performed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fb8b5ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ONE POSSIBLE APPROACH\n",
    "\n",
    "# Feature Selection\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "\n",
    "best_features = SelectKBest(score_func=chi2, k='all')\n",
    "\n",
    "fit = best_features.fit(train_x,train_y)\n",
    "\n",
    "df_scores=pd.DataFrame(fit.scores_)\n",
    "df_col=pd.DataFrame(train_x.columns)\n",
    "\n",
    "feature_score=pd.concat([df_col,df_scores],axis=1)\n",
    "feature_score.columns=['feature','score']\n",
    "feature_score.sort_values(by=['score'],ascending=False,inplace=True)\n",
    "\n",
    "print(feature_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e69f802",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANOTHER APPROACH\n",
    "importance_dict = {\n",
    "    'feature': train_x.columns\n",
    "}\n",
    "\n",
    "# on train data only\n",
    "clf = RandomForestClassifier(random_state = 1)\n",
    "clf.fit(train_x, train_y)\n",
    "feature_importance = clf.feature_importances_\n",
    "importance_dict['train'] = feature_importance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27c6dd5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ten-fold cross validation on train data\n",
    "from tqdm import notebook\n",
    "\n",
    "feature_importances = []\n",
    "kf = StratifiedKFold(n_splits = 10, shuffle = True, random_state=1)\n",
    "\n",
    "for tr_idx, val_idx in notebook.tqdm(kf.split(train_x, train_y), total = 10):\n",
    "    x_train, y_train = train_x.iloc[tr_idx], train_y[tr_idx]\n",
    "    clf = RandomForestClassifier()\n",
    "    clf.fit(x_train, y_train)\n",
    "    \n",
    "    feature_importances.append(clf.feature_importances_)\n",
    "    \n",
    "feature_importance = np.mean(feature_importances, axis = 0)\n",
    "importance_dict['train_10_fold'] = feature_importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8268f8bc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "importance_df = pd.DataFrame(importance_dict)\n",
    "for col in importance_df.columns:\n",
    "    if col == 'feature':\n",
    "        continue\n",
    "    importance_df[col] = importance_df[col] * 100 / importance_df[col].sum()\n",
    "    \n",
    "importance_df['mean'] = importance_df[[col for col in importance_df.columns if col != 'feature']].mean(axis=1)\n",
    "importance_df.sort_values('train_10_fold', ascending=False)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "26df2b16",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "85f22075",
   "metadata": {},
   "source": [
    "The less useful features, according to both the approaches above, are:\n",
    "\n",
    "- *state_others*\n",
    "- *state_RST*\n",
    "- *service_pop3*\n",
    "- *ct_ftp_cmd*\n",
    "- *state_REQ*\n",
    "- *service_others*\n",
    "- *service_ftp-data*\n",
    "- *state_FIN*\n",
    "- maybe *service_ftp*, *proto_ospf*, *service_smtp*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a79f75dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DO re-check with new values of the ensemble method\n",
    "combined_df.drop(['state_others', 'state_RST', 'service_pop3', 'state_REQ', 'service_others', 'service_ftp-data', 'state_FIN', 'ct_ftp_cmd'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17326a0c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# def plot_feature_importance(df_train, df_test, title='Feature importance', max_tree_depth=20):\n",
    "#     clf = DecisionTreeClassifier(max_depth=max_tree_depth)\n",
    "#     X = df_train\n",
    "#     y = df_test\n",
    "#     clf = clf.fit(X, y)\n",
    "\n",
    "#     # The importance of a feature is computed as the (normalized) total reduction of the criterion brought by that feature.\n",
    "#     # It is also known as the Gini importance.\n",
    "#     feature_names = df_train.columns\n",
    "#     feature_importance_df = pd.DataFrame(list(zip(clf.feature_importances_, feature_names)), columns=[\"feature_importance\", \"feature_name\"])\n",
    "#     feature_importance_df = feature_importance_df.sort_values(by='feature_importance', ascending=False)\n",
    "#     useless_features = list(feature_importance_df[feature_importance_df['feature_importance'] <= 0]['feature_name'])\n",
    "#     feature_importance_df = feature_importance_df[feature_importance_df['feature_importance'] >= 0]\n",
    "\n",
    "#     fig = px.bar(feature_importance_df, x=\"feature_name\", y=\"feature_importance\", log_y=True, title=title)\n",
    "#     fig.show(width=900, height=500)\n",
    "    \n",
    "    \n",
    "#     print(\"The following features were dropped:\")\n",
    "#     print(useless_features)\n",
    "#     return useless_features\n",
    "\n",
    "# useless_features = plot_feature_importance(train_x, train_y)\n",
    "\n",
    "# combined_df.drop(useless_features, axis=1, inplace=True)\n",
    "\n",
    "# # TO DO, specificare da ove sono stati presi questi valori\n",
    "# combined_df.drop(['proto_udp', 'swin', 'service_ftp-data', 'dttl', 'state_REQ', 'state_RST'], axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ccee7c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a09e620",
   "metadata": {},
   "outputs": [],
   "source": [
    "# update the slices \n",
    "train_x = combined_df[:len(train_x)]\n",
    "test_x = combined_df[len(train_x):]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27608321",
   "metadata": {},
   "source": [
    "## Correlation-based selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "094f9ae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_correlations = combined_df.corr()\n",
    "top_correlations(new_correlations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dda863e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df.drop(['dwin', 'stcpb_log', 'dtcpb_log', 'proto_tcp', 'ct_dst_src_ltm', 'ct_srv_dst', 'ct_dst_sport_ltm', 'ct_src_ltm', 'dpkts_log', 'dload_log', 'state_INT', 'dpkts_log', 'sloss_log', 'proto_tcp'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f965e70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# update the slices \n",
    "train_x = combined_df[:len(train_x)]\n",
    "test_x = combined_df[len(train_x):]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f954b7c2",
   "metadata": {},
   "source": [
    "### Numerosity Reduction\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e3c7d2e",
   "metadata": {},
   "source": [
    "See the Imbalance Problem in the Classification Chapter. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1541d7d6",
   "metadata": {},
   "source": [
    "### Normalization\n",
    "**Observation**: \n",
    "The distributions of each feature vary widely, this will affect our results if we use any distance-based methods for classification. \n",
    "For instance, the mean of `sload` is larger than the mean of `dur` by seven orders of magnitude, and its standard deviation is larger by eight orders of magnitude.\n",
    "\n",
    "Without performing feature value normalization, the `sload` feature would dominate, causing the model to miss out on potentially important information in the `dur` feature. We need to rescale the value. \n",
    "\n",
    "This step is usually applied to both the training and test data. The purpose of standardization is to transform the data so that it has a mean of zero and a standard deviation of one. This is done so that the data has a common scale, which is important for many machine learning algorithms that use distance metrics or assume a Gaussian distribution of the input features. By standardizing both the training and test data using the same statistics (mean and standard deviation) computed from the training data, we ensure that the test data is transformed in the same way as the training data and the results are comparable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b030911",
   "metadata": {},
   "source": [
    "TO DO provare anchea a togliere la normalizzazione"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e7284f8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_x.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e47b6400",
   "metadata": {},
   "source": [
    "The chosen scaler is RobustScaler because of its capability of maintaining small differences in the distributions, especially for outliers, this is justified by some experimentation in the classification below (initially StandardScaler was used). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e1f32c2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# produces an ill defined F score (0 division, no predicted samples)\n",
    "\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# numeric_cols = train_x.select_dtypes(exclude='object').columns\n",
    "\n",
    "# ss = StandardScaler()\n",
    "# train_x[numeric_cols] = ss.fit_transform(train_x[numeric_cols])\n",
    "# test_x[numeric_cols] = ss.transform(test_x[numeric_cols])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11be9abe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # similar results of RobustScaler\n",
    "\n",
    "# from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# numeric_cols = train_x.select_dtypes(exclude='object').columns\n",
    "\n",
    "# mms = MinMaxScaler()\n",
    "# train_x[numeric_cols] = mms.fit_transform(train_x[numeric_cols])\n",
    "# test_x[numeric_cols] = mms.transform(test_x[numeric_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1bf9313",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import RobustScaler\n",
    "\n",
    "numeric_cols = train_x.select_dtypes(exclude='object').columns\n",
    "\n",
    "rs = RobustScaler().fit(train_x[numeric_cols]);\n",
    "train_x[numeric_cols] = rs.transform(train_x[numeric_cols]);\n",
    "test_x[numeric_cols] = rs.transform(test_x[numeric_cols]);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4092b899",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df4ad7ac",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # TEST\n",
    "# from sklearn.tree import DecisionTreeClassifier\n",
    "# from sklearn.metrics import confusion_matrix, zero_one_loss, ConfusionMatrixDisplay\n",
    "\n",
    "# classifier = DecisionTreeClassifier(random_state=0)\n",
    "# classifier = classifier.fit(train_x, train_y)\n",
    "# pred_y = classifier.predict(test_x)\n",
    "# print(classification_report(test_y, pred_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3917d8b",
   "metadata": {},
   "source": [
    "# 5. Data Modelling (Classification)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e1829e4",
   "metadata": {},
   "source": [
    "**Why classification and not anomaly detection?**\n",
    "\n",
    "Classification and anomaly detection are two different machine learning tasks.\n",
    "\n",
    "**Classification** involves assigning a predefined class or category to a new instance based on its features. For example, classify a new email as spam or not spam.\n",
    "\n",
    "**Anomaly detection**, on the other hand, involves detecting instances that are different from the norm in the data. For example, detecting fraudulent transactions in a set of financial transactions.\n",
    "\n",
    "In summary, classification divides data into predefined categories, while anomaly detection identifies instances that are outside of the norm."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dd2058f",
   "metadata": {},
   "source": [
    "We have a ten-class classification problem in which each sample belongs to one of the following classes: `Fuzzers`, `Analysis`, `Backdoors`, `DoS`, `Exploits`, `Generic`, `Reconnaissance`, `Shellcode`, `Worms` and `Normal`. There are many different classification algorithms suitable for a problem like this, and many different ways to approach the problem of multiclass classification. Many classification algorithms inherently supprot multiclass data (e.g., decision trees, nearest neighbors, Naive Bayes), whereas other do not (e.g., support vector machines). Even if our algorithm of choice does not inherently support multiple classes, there are some clever techniques for effectively achieving this. \n",
    "\n",
    "TO DO remove? \n",
    "Essentially, a multiclass problem can be split into multiple binary classification problems. A strategy known as *one-versus-all*, also called *binary relevance method*, fits one classifier per class, with data belonging to the class fitted against the aggregate of all other classes. Another less commonly used strategy is *one-versus-one*, in which there are *n_classes * (n_classes - 1) / 2* classifier constructed, one for each unique pair of classes. In this case, during the prediction phase, each sample is run through all the classifiers, and the classification confidences for each of the classes are tallied. The class with the highest aggregate confidence is selectedd as the prediction result. \n",
    "One-versus-all scales linearly with the number of class and, in general, has better model interpretability because each class is only represented by one classifier (as opposed to each class being represented by *n_class - 1* classifiers for one-versus-one). TO DO remove below??? In contrast, the one-versus-one strategy does not scale well with the number of classes because of its polynomial complexity. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f43a5553",
   "metadata": {},
   "source": [
    "## 5.1 Supervised Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd444bfe",
   "metadata": {},
   "source": [
    "### Decision Tree and the Imbalance Problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b276dbda",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import confusion_matrix, zero_one_loss, ConfusionMatrixDisplay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22f278a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization purposes\n",
    "# We start with a small max_depth so we can look at the decision tree structure in a friendly way\n",
    "classifier = DecisionTreeClassifier(max_depth=5)\n",
    "classifier = classifier.fit(train_x, train_y)\n",
    "print(f\"double check shapes: X.shape = {train_x.shape}, y.shape = {train_y.shape}\")\n",
    "print(f\"model classes: {classifier.classes_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d38fa8d8",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "\n",
    "plt.figure(figsize=(30, 20), dpi=150)\n",
    "\n",
    "tree.plot_tree(classifier, feature_names = train_x.columns, fontsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0581fb7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# random_state is set to an integer to obtain a deterministic behaviour in fitting\n",
    "classifier = DecisionTreeClassifier(random_state=0)\n",
    "classifier = classifier.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dd26474",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_y = classifier.predict(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a28c7a8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(11, 11))\n",
    "disp = ConfusionMatrixDisplay.from_predictions(test_y, pred_y, xticks_rotation='vertical', ax=ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc9b0f4b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(classification_report(test_y, pred_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dc6c38a",
   "metadata": {},
   "source": [
    "With just a few lines of code and no tuning at all, a 77% classification accuracy is obtained. However, this number is quite meaningless without considering the distribution of the test set (shown below). We know that such a measure is not acceptable for an unbalanced dataset, because we are interested in the *minority* class. If we take a look at some other measure like the **precision** (percentage of tuples labeled as positive and actually such, *TP/(TP+FP)*) and the **recall**  (percentage of positive tuples labeled as such, *TP/P*) the results are not very good. For example, the 'Analysis' attack category has a precision = 2% and a recall = 9%. \n",
    "A good parameter to look at is the F1-Score, e.g. an harmonic mean of precision and recall."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07a9eea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_attack_cats = test_y.value_counts()\n",
    "test_attack_cats.plot(kind='barh', logx=True, figsize=(20,10), fontsize=20);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae006214",
   "metadata": {},
   "source": [
    "In the confusion matrix, the diagonal values are the counts of the correctly classified samples. Each row represents the true class, and each column represents the predicted class. For instance, the number in the second row and in third column represents the number of samples that are actually of class `Backdoor` that were classfied as `DoS`.\n",
    "\n",
    "Simlarly to the training set, the test distribution is not balanced across categories:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26c5de09",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_y.value_counts().apply(lambda x: x / float(len(test_y)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbb34a79",
   "metadata": {},
   "source": [
    "TO DO correct these values. \n",
    "We see that the 44% of the test data belong to the `Normal` class, 23% to the `Generic` one, 14% to `Exploits`, 7% to `Fuzzers`, whereas only the 0,005% of the data belongs to the `Worms` class, the 0,04% belongs to the `Shellcode`, 0,07% to `Backdoor` and 0,08% to `Analysis`. We can see the problem in the `Shellcode` row for example, the number of times it is correctly classified is similar to the number of times it is wrongly classified. It could have been not enough information for the trained model to learn from the latter classes to correctly identify them. We must face the problem of class imbalance. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f24e33f",
   "metadata": {},
   "source": [
    "### Sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ace6107",
   "metadata": {},
   "source": [
    "As we know, there are two possible remedies: undersampling (e.g., prioritize the removal of samples that are very similar to other samples that will remain in the dataset) and oversampling (e.g., generate synthetic data points for minority classes using SMOTE). A popular method is to first oversample the minority class and then undersample to tighten the class distribution discrepancy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14bace8f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(pd.Series(train_y).value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9abd257c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install imblearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e2fd585",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "mean_class_size = int(pd.Series(train_y).value_counts().sum() / 10)\n",
    "\n",
    "# a lot of values were tried\n",
    "strategy = { \n",
    "            #'Fuzzers': mean_class_size, \n",
    "            'DoS': 40000, \n",
    "            'Analysis': 40000, \n",
    "            'Backdoor': 40000, \n",
    "            'Shellcode': 40000, \n",
    "            'Worms': 40000\n",
    "           }\n",
    "\n",
    "sm = SMOTE(sampling_strategy = strategy, random_state = 0)\n",
    "train_x_sm, train_y_sm = sm.fit_resample(train_x, train_y)\n",
    "print(pd.Series(train_y_sm).value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b03ea6c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_attack_cats = train_y_sm.value_counts()\n",
    "test_attack_cats.plot(kind='barh', logx=True, figsize=(20,10), fontsize=20);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f17961e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# OVERFITTING CHECK (commented because time-consuming, also tried with classification_report)\n",
    "# values = [i for i in range(10, 25)]\n",
    "# for i in values:\n",
    "#     print(f\"Value: {i}\\n\")\n",
    "#     classifier = DecisionTreeClassifier(max_depth=i, random_state=0)\n",
    "#     classifier = classifier.fit(train_x_sm, train_y_sm)\n",
    "#     pred_yt = classifier.predict(test_x)\n",
    "#     print(accuracy_score(test_y, pred_yt))\n",
    "#     pred_yt = classifier.predict(train_x_sm)\n",
    "#     print(accuracy_score(train_y_sm, pred_yt))\n",
    "#     print(\" \")\n",
    "\n",
    "dt = DecisionTreeClassifier(max_depth=25, random_state=0)\n",
    "classifier = classifier.fit(train_x_sm, train_y_sm)\n",
    "pred_y = classifier.predict(test_x)\n",
    "fig, ax = plt.subplots(figsize=(11, 11))\n",
    "disp = ConfusionMatrixDisplay.from_predictions(test_y, pred_y, xticks_rotation='vertical', ax=ax)\n",
    "plt.show()\n",
    "print(classification_report(test_y, pred_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b99b768",
   "metadata": {},
   "source": [
    "We can see an overfitting problem after a depth of 16 levels, thanks to the loop test. This is why we set max_depth to 16. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abd39e4a",
   "metadata": {},
   "source": [
    "TO DO correct Here a lot of experimentation can be made: my idea was to try first SMOTE to all the minority classes with a sampling set to *mean_class_size*, then SMOTE to all the minority classes with the strategy set to *auto*, then some experimentation mixing these values. For example, applying SMOTE only to those features with an F-score less than 0.50, or do the latter but adding also those features that worsen their measures (like Worms), and something similar. I found that the best, worst, solution is applying SMOTE to all those features with an F-score less than 50%. When I evaluated these combinations I evaluated the total sum of the F-scores of all the features. When I said best/worst is because the relative solution is in any case worst with respect to the base one without over-sampling. \n",
    "\n",
    "Let's see what happens applying also under-sampling:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35507249",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pd.Series(train_y_sm).value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef9f8892",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "# mean_class_size = int(pd.Series(train_y_sm).value_counts().sum() / 10)\n",
    "\n",
    "# a lot of combinations has been tried\n",
    "ratio = {\n",
    "         'Normal': mean_class_size, \n",
    "         'Exploits': mean_class_size,\n",
    "         'Generic': mean_class_size\n",
    "        }\n",
    "\n",
    "rus = RandomUnderSampler(sampling_strategy = ratio, random_state = 0)\n",
    "train_x_sm_rus, train_y_sm_rus = rus.fit_resample(train_x_sm, train_y_sm)\n",
    "print(pd.Series(train_y_sm_rus).value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b48fac5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_attack_cats_sm_rus = train_y_sm_rus.value_counts()\n",
    "test_attack_cats_sm_rus.plot(kind='barh', logx=True, figsize=(20,10), fontsize=20);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd1f7238",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OVERFITTING CHECK (commented because time-consuming)\n",
    "# values = [i for i in range(10, 30)]\n",
    "# for i in values:\n",
    "#     print(f\"Value: {i}\\n\")\n",
    "#     classifier = DecisionTreeClassifier(max_depth=i, random_state=0)\n",
    "#     classifier = classifier.fit(train_x_sm_rus, train_y_sm_rus)\n",
    "#     pred_yt = classifier.predict(test_x)\n",
    "#     print(classification_report(test_y, pred_yt))\n",
    "#     pred_yt = classifier.predict(train_x_sm_rus)\n",
    "#     print(classification_report(train_y_sm_rus, pred_yt))\n",
    "#     print(\" \")\n",
    "\n",
    "classifier = DecisionTreeClassifier(max_depth=21, random_state=0)\n",
    "classifier = classifier.fit(train_x_sm_rus, train_y_sm_rus)\n",
    "pred_y = classifier.predict(test_x)\n",
    "fig, ax = plt.subplots(figsize=(11, 11))\n",
    "disp = ConfusionMatrixDisplay.from_predictions(test_y, pred_y, xticks_rotation='vertical', ax=ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a3a3604",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(test_y, pred_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3d85cf6",
   "metadata": {},
   "source": [
    "Also here, some experimentation has been done. We can notice that the scores change a bit for some features but basically their sum remains the same. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b3a7323",
   "metadata": {},
   "source": [
    "Our last chance is to perform only undersampling:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f9ed1a1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# mean_class_size = int(pd.Series(train_y_sm).value_counts().sum() / 10)\n",
    "\n",
    "# a lot of combinations has been tried\n",
    "ratio = {\n",
    "         'Normal': mean_class_size, \n",
    "         'Exploits': mean_class_size,\n",
    "         'Generic': mean_class_size\n",
    "        }\n",
    "\n",
    "orus = RandomUnderSampler(sampling_strategy = ratio, random_state = 0)\n",
    "train_x_orus, train_y_orus = orus.fit_resample(train_x, train_y)\n",
    "print(pd.Series(train_y_orus).value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8217b5bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_attack_cats_orus = train_y_orus.value_counts()\n",
    "test_attack_cats_orus.plot(kind='barh', logx=True, figsize=(20,10), fontsize=20);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a4e934d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OVERFITTING CHECK (commented because time-consuming)\n",
    "# values = [i for i in range(10, 30)]\n",
    "# for i in values:\n",
    "#     print(f\"Value: {i}\\n\")\n",
    "#     classifier = DecisionTreeClassifier(max_depth=i, random_state=0)\n",
    "#     classifier = classifier.fit(train_x_orus, train_y_orus)\n",
    "#     pred_yt = classifier.predict(test_x)\n",
    "#     print(classification_report(test_y, pred_yt))\n",
    "#     pred_yt = classifier.predict(train_x_orus)\n",
    "#     print(classification_report(train_y_orus, pred_yt))\n",
    "#     print(\" \")\n",
    "\n",
    "classifier = DecisionTreeClassifier(max_depth=12, random_state=0)\n",
    "classifier = classifier.fit(train_x_orus, train_y_orus)\n",
    "pred_y = classifier.predict(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84427608",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(classification_report(test_y, pred_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1d3a618",
   "metadata": {},
   "source": [
    "Also in this case some experiments have been done, but the point remains the same, we can get some better behaviour in classifying some minority classes but with no such a general great improvement. \n",
    "We can conclude that some features like *Analysis* and *Backdoors* probably do not have a suitable fingerprint on the network statistics, because even raising up their instances, making them the majority classes (e.g., first oversample them to the max, and then undersample the other major categories), makes a little difference on their metrics. Another possible reason is the nature of the data that were sampled when the dataset was created. \n",
    "Furthermore, the unbalanced multiclass classification problem is hard to solve.\n",
    "\n",
    "In the following i decided to apply the **stratified K fold cross validation** to choose the right sampling to maintain (spoiler: the application of both SMOTE and RandomUnderSampling). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e8e6689",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# this is not extremely necessary because the test set is not too small\n",
    "# but is preferred considering the unbalanced nature of the dataset\n",
    "\n",
    "def applyStratifiedKFold(classifier):\n",
    "    skf = StratifiedKFold(n_splits=10, shuffle=True)\n",
    "\n",
    "    df_all = pd.concat([train_x, test_x], axis=0)\n",
    "    gt_all = pd.concat([train_y, test_y], axis=0)\n",
    "\n",
    "    list_df = []\n",
    "    list_accuracy = []\n",
    "\n",
    "    k = 1\n",
    "    for train_idx, test_idx in skf.split(df_all, gt_all):\n",
    "\n",
    "        print(f'FOLD {k}:')\n",
    "\n",
    "        # fit and predict using classifier\n",
    "        x_tr = df_all.iloc[train_idx]\n",
    "        y_tr = gt_all.iloc[train_idx]\n",
    "        x_test = df_all.iloc[test_idx]\n",
    "        y_test = gt_all.iloc[test_idx]\n",
    "\n",
    "        clf = classifier\n",
    "        clf.fit(x_tr, y_tr)\n",
    "        y_pred = clf.predict(x_test)\n",
    "\n",
    "        # compute classification report\n",
    "        cr = classification_report(y_test, y_pred, output_dict = True)\n",
    "\n",
    "        # store accuracy\n",
    "        list_accuracy.append(cr['accuracy'])\n",
    "\n",
    "        # store per-class metrics as a dataframe\n",
    "        df = pd.DataFrame({k:v for k,v in cr.items() if k != 'accuracy'})\n",
    "        display(df)\n",
    "        list_df.append(df)\n",
    "        k += 1\n",
    "        print(\"\")\n",
    "    \n",
    "    return list_df, list_accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66fd9e97",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_df, list_accuracy = applyStratifiedKFold(DecisionTreeClassifier())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "072bee5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute average per-class metrics  \n",
    "def computeAverageMetrics(df_list):\n",
    "    df_concat = pd.concat(df_list)\n",
    "    grouped_by_row_index = df_concat.groupby(df_concat.index)\n",
    "    df_avg = grouped_by_row_index.mean()\n",
    "    df_avg.transpose()\n",
    "    return df_avg\n",
    "\n",
    "# compute average accuracy\n",
    "def computeAverageAccuracy(accuracy_list):\n",
    "    accuracy_avg = np.mean(accuracy_list)\n",
    "    print(\"Average Accuracy score == {:.2f} %\".format(accuracy_avg*100))\n",
    "    \n",
    "# compute average F1-score\n",
    "def computeAverageF1Score(avg_df):\n",
    "    f1_avg = avg_df.transpose()['f1-score'].mean()\n",
    "    print(\"Average F1-score == {:.2f} %\".format(f1_avg*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28ca7ef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_avg = computeAverageMetrics(list_df)\n",
    "df_avg.transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b234ca16",
   "metadata": {},
   "outputs": [],
   "source": [
    "computeAverageAccuracy(list_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1cd324a",
   "metadata": {},
   "outputs": [],
   "source": [
    "computeAverageF1Score(df_avg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b17c8526",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "858d619e",
   "metadata": {},
   "source": [
    "dal file IoT dei salvati:\n",
    "    - linear regression\n",
    "    - linear support vector machine? mi sembrava di no\n",
    "    - KNN\n",
    "    - Random forest / decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a317ce28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 20 minutes running\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# one-versus-rest\n",
    "logr_classifier = LogisticRegression(dual=False, class_weight='balanced', max_iter=5000, solver='newton-cg', multi_class='ovr', n_jobs=-1)\n",
    "logr_classifier.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2143de44",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_y = logr_classifier.predict(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "577edeee",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(11, 11))\n",
    "disp = ConfusionMatrixDisplay.from_predictions(test_y, pred_y, xticks_rotation='vertical', ax=ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce02c668",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(test_y, pred_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35bcffa2-8ec6-46bf-bea2-9c66cbe0d27a",
   "metadata": {},
   "source": [
    "## Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b0c586f-9b01-49a2-951a-11d213751d33",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "lr_multi = LinearRegression()\n",
    "lr_multi.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e758046",
   "metadata": {},
   "source": [
    "## Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcf49326-8d4f-4945-ad18-e75abe5f2eb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# support vector machine\n",
    "# LinearSVC implements “one-vs-the-rest” multi-class strategy, thus training n_classes models\n",
    "# it scales better than SVC with kernel=linear\n",
    "\n",
    "# VERY LONG RUNNING TIME\n",
    "\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "lsvm = LinearSVC(dual=False, class_weight='balanced', max_iter=15000)\n",
    "lsvm.fit(train_x, train_y) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "654f4252-10bf-456e-8cc4-01b65be13ba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_y = lsvm.predict(test_x)\n",
    "print(classification_report(test_y, pred_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ce6bb1b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(11, 11))\n",
    "disp = ConfusionMatrixDisplay.from_predictions(test_y, pred_y, xticks_rotation='vertical', ax=ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5b34d2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "skf = StratifiedKFold(n_splits=10, shuffle=True)\n",
    "\n",
    "print('here')\n",
    "df_all = pd.concat([train_x, test_x], axis=0)\n",
    "gt_all = pd.concat([train_y, test_y], axis=0)\n",
    "\n",
    "list_df = []\n",
    "list_accuracy = []\n",
    "print('here1')\n",
    "k = 1\n",
    "for train_idx, test_idx in skf.split(df_all, gt_all):\n",
    "\n",
    "    print(f'FOLD {k}:')\n",
    "\n",
    "    # fit and predict using classifier\n",
    "    x_tr = df_all.iloc[train_idx]\n",
    "    y_tr = gt_all.iloc[train_idx]\n",
    "    x_test = df_all.iloc[test_idx]\n",
    "    y_test = gt_all.iloc[test_idx]\n",
    "    \n",
    "    print('pre')\n",
    "    clf = LinearSVC(dual=False, class_weight='balanced', max_iter=15000)\n",
    "    print('gas')\n",
    "    clf.fit(x_tr, y_tr)\n",
    "    print('post')\n",
    "    y_pred = clf.predict(x_test)\n",
    "    print('predicted')\n",
    "    # compute classification report\n",
    "    cr = classification_report(y_test, y_pred, output_dict = True)\n",
    "\n",
    "    # store accuracy\n",
    "    list_accuracy.append(cr['accuracy'])\n",
    "\n",
    "    # store per-class metrics as a dataframe\n",
    "    df = pd.DataFrame({k:v for k,v in cr.items() if k != 'accuracy'})\n",
    "    display(df)\n",
    "    list_df.append(df)\n",
    "    k += 1\n",
    "    print(\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d6098f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_concat = pd.concat(list_df)\n",
    "grouped_by_row_index = df_concat.groupby(df_concat.index)\n",
    "df_avg = grouped_by_row_index.mean()\n",
    "df_avg.transpose()\n",
    "\n",
    "accuracy_avg = np.mean(list_accuracy)\n",
    "print(\"Average Accuracy score == {:.2f} %\".format(accuracy_avg*100))\n",
    "    \n",
    "f1_avg = df_avg.transpose()['f1-score'].mean()\n",
    "print(\"Average F1-score == {:.2f} %\".format(f1_avg*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6028c102",
   "metadata": {},
   "source": [
    "## K Nearest Neighbours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "271a5997",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_jobs=-1)\n",
    "knn.fit(train_x,train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5962f20",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_y = knn.predict(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b79fcd1d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(classification_report(test_y, pred_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cbebbe6",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "044b0f7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "randf = RandomForestClassifier(class_weight = 'balanced', n_jobs=-1)\n",
    "randf.fit(train_x, train_y)\n",
    "\n",
    "pred_y = randf.predict(test_x)\n",
    "print(classification_report(test_y, pred_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "386b81a1",
   "metadata": {},
   "source": [
    "## Multi-layer Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75921ec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = MLPClassifier(random_state=123, solver='adam', max_iter=10000)\n",
    "mlp.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1ecc1c4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pred_y = mlp.predict(test_x)\n",
    "print(classification_report(test_y, pred_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "223874b4",
   "metadata": {},
   "source": [
    "# TEST for class change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "771dfca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f60a5344",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_y_9 = train_y.copy(deep=True)\n",
    "train_y_9.loc[train_y_9 == 'Backdoor'] = 'Backdoor_or_Dos'\n",
    "train_y_9.loc[train_y_9 == 'DoS'] = 'Backdoor_or_Dos'\n",
    "\n",
    "\n",
    "test_y_9 = test_y.copy(deep=True)\n",
    "test_y_9.loc[test_y_9 == 'Backdoor'] = 'Backdoor_or_Dos'\n",
    "test_y_9.loc[test_y_9 == 'DoS'] = 'Backdoor_or_Dos'\n",
    "test_y_9.sample(100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac202a81",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = DecisionTreeClassifier(random_state=0)\n",
    "classifier = classifier.fit(train_x, train_y_9)\n",
    "pred_y = classifier.predict(test_x)\n",
    "print(classification_report(test_y_9, pred_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cea0279",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(11, 11))\n",
    "disp = ConfusionMatrixDisplay.from_predictions(test_y_9, pred_y, xticks_rotation='vertical', ax=ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3eac016",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_y_7 = train_y_9.copy(deep=True)\n",
    "train_y_7.loc[train_y_7 == 'Backdoor_or_Dos'] = 'BADE'\n",
    "train_y_7.loc[train_y_7 == 'Analysis'] = 'BADE'\n",
    "train_y_7.loc[train_y_7 == 'Exploits'] = 'BADE'\n",
    "\n",
    "\n",
    "test_y_7 = test_y_9.copy(deep=True)\n",
    "test_y_7.loc[test_y_7 == 'Backdoor_or_Dos'] = 'BADE'\n",
    "test_y_7.loc[test_y_7 == 'Analysis'] = 'BADE'\n",
    "test_y_7.loc[test_y_7 == 'Exploits'] = 'BADE'\n",
    "\n",
    "test_y_7.sample(100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0341ed76",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "classifier = DecisionTreeClassifier(random_state=0)\n",
    "classifier = classifier.fit(train_x, train_y_7)\n",
    "pred_y = classifier.predict(test_x)\n",
    "print(classification_report(test_y_7, pred_y))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c4ee1ec",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(11, 11))\n",
    "disp = ConfusionMatrixDisplay.from_predictions(test_y_7, pred_y, xticks_rotation='vertical', ax=ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f97df6f7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_y_2 = train_y_7.copy(deep=True)\n",
    "train_y_2.loc[train_y_7 != 'Normal'] = 'Attack'\n",
    "\n",
    "\n",
    "test_y_2 = test_y_7.copy(deep=True)\n",
    "test_y_2.loc[test_y_2 != 'Normal'] = 'Attack'\n",
    "\n",
    "\n",
    "test_y_2.sample(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "728a8b1b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "classifier = DecisionTreeClassifier(random_state=0)\n",
    "classifier = classifier.fit(train_x, train_y_2)\n",
    "pred_y_2 = classifier.predict(test_x)\n",
    "print(classification_report(test_y_2, pred_y_2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a169983f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(11, 11))\n",
    "disp = ConfusionMatrixDisplay.from_predictions(test_y_2, pred_y_2, xticks_rotation='vertical', ax=ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dafb1f47",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# randf = RandomForestClassifier(class_weight = 'balanced', n_jobs=-1)\n",
    "# randf.fit(train_x, train_y_2)\n",
    "\n",
    "# pred_y_2 = randf.predict(test_x)\n",
    "# print(classification_report(test_y_2, pred_y_2))\n",
    "\n",
    "mlp = MLPClassifier(random_state=123, solver='adam', max_iter=10000)\n",
    "mlp.fit(train_x, train_y_2)\n",
    "pred_y_2 = mlp.predict(test_x)\n",
    "print(classification_report(test_y_2, pred_y_2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ad5bb99",
   "metadata": {},
   "source": [
    "# Unsupervised Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd6484bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_clustering(y_true, y_pred):\n",
    "    # Matrix $C$ such that $C_{ij}$ is the number of samples in true class $i$ and in predicted cluster $j$.\n",
    "    cm = contingency_matrix(y_true, y_pred)\n",
    "    print(f'contingency matrix: \\n {cm}')\n",
    "    for enu, row in enumerate(cm):\n",
    "        print(f'Row{enu}: sum = {sum(row)}')    \n",
    "    homogeneity, completeness, v_measure = homogeneity_completeness_v_measure(y_true, y_pred)\n",
    "#   homogeneity is high if all the clusters contain only data points which are members of a single class.\n",
    "    print(f'homogeneity score: {homogeneity}')\n",
    "#   completeness is high if all the data points that are members of a given class are elements of the same cluster.\n",
    "    print(f'completeness score: {completeness}')\n",
    "    print(f'v-measure score: {v_measure}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caea6ddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y_bin = train_y.apply(lambda x: 'normal' if x == 'Normal' else 'attack')\n",
    "train_y_bin.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa86eb75",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def plot_pca(X,Y):\n",
    "    # Use PCA to reduce dimensionality so we can visualize the dataset on a 2d plot\n",
    "    pca = PCA(n_components=2)\n",
    "\n",
    "    data_pca = pca.fit_transform(X)\n",
    "\n",
    "    print(f'percentage of variance explained by principal components: {pca.explained_variance_ratio_}')\n",
    "    print(f'sum: {sum(pca.explained_variance_ratio_)}')\n",
    "\n",
    "    plt.figure(figsize=(15,10))\n",
    "    colors = ['navy', 'turquoise', 'darkorange', 'red', 'purple', 'green', 'pink', 'yellow', 'black', 'orange']\n",
    "    \n",
    "    for color, cat in zip(colors, np.unique(Y)):\n",
    "        plt.scatter(data_pca[Y==cat, 0], data_pca[Y==cat, 1],\n",
    "                    color=color, alpha=.8, lw=2, label=cat)\n",
    "    plt.legend(loc='best', shadow=False, scatterpoints=1)\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    \n",
    "# %matplotlib notebook\n",
    "plot_pca(train_x, train_y)\n",
    "plot_pca(train_x, train_y_bin)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a51a415",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def apply_kmeans(X, y, k_values, n_components = 2):\n",
    "    for k in k_values:\n",
    "        print(f'k = {k}')\n",
    "        kmeans = KMeans(n_clusters = k, random_state = 17).fit(X)\n",
    "        pred_y = kmeans.labels_\n",
    "        evaluate_clustering(y, pred_y)\n",
    "\n",
    "        \n",
    "# If 0 < n_components < 1 and svd_solver == 'full' (automatically selected), \n",
    "# select the number of components such that \n",
    "# the amount of variance that needs to be explained is greater \n",
    "# than the percentage specified by n_components.\n",
    "for components in [0.95,2,None]: # arguments for the PCA reduction, different cases\n",
    "    print()\n",
    "    if components:\n",
    "        print(components)\n",
    "        pca = PCA(n_components=components)\n",
    "        data_clustering = pca.fit_transform(train_x)\n",
    "    else:\n",
    "        data_clustering = train_x\n",
    "    print(f'[transformed] space shape: {data_clustering.shape}')\n",
    "    apply_kmeans(data_clustering, train_y, [10])\n",
    "#     apply_kmeans(data_pca,train_y,[8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c7277e6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for components in [0.95,2,None]:\n",
    "    print()\n",
    "    if components:\n",
    "        pca = PCA(n_components = components)\n",
    "        data_clustering = pca.fit_transform(train_x)\n",
    "    else:\n",
    "        data_clustering = train_x\n",
    "    print(f'[transformed] space shape: {data_clustering.shape}')\n",
    "    apply_kmeans(data_clustering, train_y_bin, [2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa2d4f9e",
   "metadata": {},
   "source": [
    "As we can see from the previous results, this dataset is absolutely not suitable for a clustering approach. \n",
    "### TODO comments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31dd1a01",
   "metadata": {},
   "source": [
    "# Outlier Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "598053b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y.value_counts().index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aa15df8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "final_indices = []\n",
    "for net_type in train_y.value_counts().index:\n",
    "    if net_type == 'Normal':\n",
    "        final_indices.extend(train_y[train_y == net_type].index.values)\n",
    "    final_indices.extend(train_y[train_y == net_type].sample(10).index.values)\n",
    "len(final_indices)\n",
    "train_y_sample = train_y.loc[final_indices]\n",
    "train_y_bin_sample = train_y_bin.loc[final_indices]\n",
    "print(train_y_sample.value_counts())\n",
    "print(train_y_bin_sample.value_counts())\n",
    "train_x_sample = train_x.loc[final_indices,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fc6d27d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def apply_LOF(X, contamination):\n",
    "    lof = LOF(contamination = contamination)\n",
    "    y_lof = lof.fit_predict(X)\n",
    "    unique, counts = np.unique(y_lof, return_counts = True)\n",
    "    print(dict(zip(unique, counts)))\n",
    "    pred_y = np.minimum(y_lof,0)*(-1)\n",
    "    return pred_y\n",
    "\n",
    "pca = PCA(n_components=0.95)\n",
    "data_clustering = pca.fit_transform(train_x_sample)\n",
    "\n",
    "print(f'[transformed] space shape: {data_clustering.shape}')\n",
    "\n",
    "for contamination in [0.0005, 0.001, 'auto']:\n",
    "    print('contamination', contamination)\n",
    "    pred_y = apply_LOF(data_clustering, contamination)\n",
    "    evaluate_clustering(train_y_sample, pred_y)\n",
    "    evaluate_clustering(train_y_bin_sample, pred_y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "add2a0b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y_fuzzers = train_y.apply(lambda x: 'outlier' if x == 'Fuzzers' else 'normal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5bdacf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=0.95)\n",
    "data_clustering = pca.fit_transform(train_x)\n",
    "print(f'[transformed] space shape: {data_clustering.shape}')\n",
    "\n",
    "for contamination in [0.0005,'auto']:\n",
    "    print()\n",
    "    print('contamination', contamination)\n",
    "    pred_y = apply_LOF(data_clustering, contamination)\n",
    "    evaluate_clustering(train_y_fuzzers, pred_y)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
